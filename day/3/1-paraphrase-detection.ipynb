{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Similar Statements\n",
    "\n",
    "Let's take a step back for a second. My end goal for all my learning is to build a team of AI Agents to work together and solve problems. When these agents communicate, it will be important to distinguish if they are talking about the same thing.\n",
    "\n",
    "This notebook is to use prompt engineering and tricky statements to see how well the LLM can detect paraphrasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.gpt4all import GPT4All\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = PromptTemplate.from_template((\n",
    "    \"{instructions} \"\n",
    "    \"Valid answers are 'yes' or 'no'.\\n\\n\"\n",
    "    \"Statement 1: {statement1}\\n\"\n",
    "    \"Statement 2: {statement2}\\n\\n\"\n",
    "    \"Answer: \"\n",
    "))\n",
    "\n",
    "prompts = [\n",
    "    base_prompt.partial(instructions=\"Given two statements, check if they paraphrase each other.\"),\n",
    "    base_prompt.partial(instructions=\"Given two statements, check if they imply the same meaning.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_prompts(model, statements):\n",
    "    for prompt in prompts:\n",
    "        print(f\"{prompt.partial_variables['instructions'].strip('.')} :: \", (prompt | model).invoke({\n",
    "            \"statement1\": statements[0],\n",
    "            \"statement2\": statements[1],\n",
    "        }).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.gpt4all import GPT4All\n",
    "\n",
    "# mistral-7b download available from the gpt4all website. Use the \"Model Explorer\"\n",
    "# https://gpt4all.io/\n",
    "llm = GPT4All(\n",
    "    model=\"../../models/mistral-7b-openorca.Q4_0.gguf\",\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it a simple task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two statements, check if they paraphrase each other ::  Yes\n",
      "Given two statements, check if they imply the same meaning ::  Yes\n"
     ]
    }
   ],
   "source": [
    "test_all_prompts(llm, [\n",
    "    \"I like to eat apples.\",\n",
    "    \"I enjoy eating apples.\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is a bit tricky -- because in my opinion they are not paraphrases. Thankfully the second prompt catches it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two statements, check if they paraphrase each other ::  Yes\n",
      "Given two statements, check if they imply the same meaning ::  No\n"
     ]
    }
   ],
   "source": [
    "test_all_prompts(llm, [\n",
    "    \"I like to eat apples.\",\n",
    "    \"Apples are my favorite fruit because they can be red or green.\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prompt use case is a bit more complicated because some key words are duplicated between the two statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two statements, check if they paraphrase each other ::  No\n",
      "Given two statements, check if they imply the same meaning ::  No\n"
     ]
    }
   ],
   "source": [
    "test_all_prompts(llm, [\n",
    "    \"The Taj Mahal is a great tourist attraction in India.\",\n",
    "    \"The Taj Mahal is in India.\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two statements, check if they paraphrase each other ::  Yes\n",
      "Given two statements, check if they imply the same meaning ::  yes\n"
     ]
    }
   ],
   "source": [
    "test_all_prompts(llm, [\n",
    "    \"Thunder is the sound caused by lightning. Children are often scared of thunder, even though it can't hurt them.\",\n",
    "    \"The sudden increase in temperature and hence pressure caused by the lightning produces rapid expansion of the air in the path of a lightning bolt. This rapid expansion of air results in a sonic shock wave which can be scary.\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two statements, check if they paraphrase each other ::  Yes\n",
      "Given two statements, check if they imply the same meaning ::  Yes\n"
     ]
    }
   ],
   "source": [
    "test_all_prompts(llm, [\n",
    "    \"I want to increase my income.\",\n",
    "    \"I wish I worked at a job that paid more money.\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two statements, check if they paraphrase each other ::  No\n",
      "Given two statements, check if they imply the same meaning ::  no\n"
     ]
    }
   ],
   "source": [
    "test_all_prompts(llm, [\n",
    "    \"The box is made of cardboard.\",\n",
    "    \"The box is made of wood.\",\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
